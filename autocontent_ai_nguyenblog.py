# -*- coding: utf-8 -*-
"""AutoContent-AI-NguyenBlog.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MKVCMLi0RoctwcDAG5u39IE6HHSCpezt
"""

# C√†i ƒë·∫∑t th∆∞ vi·ªán
!pip install python-telegram-bot nest_asyncio PyMuPDF pytesseract Pillow python-docx openai

# Import
import nest_asyncio
nest_asyncio.apply()

from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, filters, ContextTypes, CommandHandler, ConversationHandler
import fitz  # PyMuPDF
import pytesseract
from PIL import Image
import io
from docx import Document
from openai import OpenAI
import os

# Th√™m OpenAI API Key
client = OpenAI(api_key="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")

TOKEN = '7604536464:AAEAs7WZG0PvoBbdojFC_agY-QX1oTAzp_I'

# ƒê·ªãnh nghƒ©a tr·∫°ng th√°i cho ConversationHandler
AWAITING_PROMPT = 1

# Dictionary l∆∞u tr·ªØ vƒÉn b·∫£n c·ªßa t·ª´ng ng∆∞·ªùi d√πng
user_text_data = {}

async def query_openai(prompt, text):
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            store=True,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": text}
            ],
            max_tokens=1000  # Gi·ªõi h·∫°n ph·∫£n h·ªìi t·ªëi ƒëa 1000 tokens (~3000-4000 k√Ω t·ª±)
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"‚ö†Ô∏è L·ªói khi g·ªçi API OpenAI: {str(e)}"

async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        file = await update.message.document.get_file()
        file_path = f"./{update.message.document.file_name}"

        # T·∫£i file v·ªÅ m√°y ch·ªß (Google Colab)
        await file.download_to_drive(file_path)
        await update.message.reply_text("‚úÖ ƒê√£ nh·∫≠n file, ƒëang x·ª≠ l√Ω...")

        full_text = ""

        if file_path.lower().endswith(".pdf"):
            # X·ª≠ l√Ω file PDF ƒë·ªÉ l·∫•y to√†n b·ªô text
            pdf = fitz.open(file_path)
            for page_num in range(len(pdf)):
                page = pdf.load_page(page_num)
                text = page.get_text()
                if text.strip():
                    full_text += text
                else:
                    # X·ª≠ l√Ω trang PDF d·∫°ng ·∫£nh
                    pix = page.get_pixmap()
                    img_bytes = pix.tobytes()
                    img = Image.open(io.BytesIO(img_bytes))
                    ocr_text = pytesseract.image_to_string(img, lang="eng+vie")
                    full_text += ocr_text
            pdf.close()

        elif file_path.lower().endswith(".docx"):
            # X·ª≠ l√Ω file Word
            doc = Document(file_path)
            full_text = '\n'.join([para.text for para in doc.paragraphs])

        else:
            await update.message.reply_text("‚ö†Ô∏è ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.")
            return

        # L∆∞u vƒÉn b·∫£n ƒë·ªÉ ch·ªù prompt t·ª´ ng∆∞·ªùi d√πng
        user_text_data[update.message.chat_id] = full_text
        await update.message.reply_text("üìå Vui l√≤ng nh·∫≠p prompt ƒë·ªÉ x·ª≠ l√Ω n·ªôi dung vƒÉn b·∫£n.")
        return AWAITING_PROMPT

    except Exception as e:
        await update.message.reply_text(f"‚ö†Ô∏è ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {str(e)}")

async def handle_prompt(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.chat_id
    if user_id not in user_text_data:
        await update.message.reply_text("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n·ªôi dung vƒÉn b·∫£n. Vui l√≤ng g·ª≠i l·∫°i file tr∆∞·ªõc.")
        return ConversationHandler.END

    prompt = update.message.text
    full_text = user_text_data.pop(user_id)  # L·∫•y n·ªôi dung v√† x√≥a kh·ªèi b·ªô nh·ªõ

    await update.message.reply_text("ü§ñ ƒêang g·ª≠i n·ªôi dung ƒë·∫øn ChatGPT...")
    ai_response = await query_openai(prompt, full_text)

    # T·∫°o file TXT ƒë·ªÉ g·ª≠i ng∆∞·ª£c l·∫°i Telegram
    response_file_path = f"response_{user_id}.txt"
    with open(response_file_path, "w", encoding="utf-8") as file:
        file.write(ai_response)

    # G·ª≠i file TXT ƒë·∫øn ng∆∞·ªùi d√πng
    with open(response_file_path, "rb") as file:
        await update.message.reply_document(file)

    return ConversationHandler.END

async def main():
    app = ApplicationBuilder().token(TOKEN).build()

    conv_handler = ConversationHandler(
        entry_points=[MessageHandler(filters.Document.PDF | filters.Document.DOCX, handle_file)],
        states={
            AWAITING_PROMPT: [MessageHandler(filters.TEXT & ~filters.COMMAND, handle_prompt)]
        },
        fallbacks=[]
    )

    app.add_handler(conv_handler)

    print("ü§ñ Bot ƒëang ch·∫°y...")
    await app.run_polling()

import asyncio
asyncio.run(main())



!apt-get update -y
!apt-get install tesseract-ocr -y
!apt-get install tesseract-ocr-vie -y
!apt-get install libtesseract-dev -y

!which tesseract
!tesseract --version